(0l(B Arguments defined(0qqqqqqqqwqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk(B
(0x(B Parameter                (0x(B Value                                        (0x(B
(0tqqqqqqqqqqqqqqqqqqqqqqqqqqnqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqu(B
(0x(B model.arch               (0x(B vit_b                                        (0x(B
(0x(B model.pretrained         (0x(B 1                                            (0x(B
(0x(B model.ckpt_path          (0x(B                                              (0x(B
(0x(B model.add_normalization  (0x(B 0                                            (0x(B
(0x(B model.not_original       (0x(B 1                                            (0x(B
(0x(B model.updated            (0x(B 0                                            (0x(B
(0x(B model.model_ema          (0x(B 1.0                                          (0x(B
(0x(B model.freeze_some        (0x(B 0                                            (0x(B
(0x(B model.early              (0x(B 1                                            (0x(B
(0x(B resolution.min_res       (0x(B 224                                          (0x(B
(0x(B resolution.max_res       (0x(B 224                                          (0x(B
(0x(B resolution.end_ramp      (0x(B 0                                            (0x(B
(0x(B resolution.start_ramp    (0x(B 0                                            (0x(B
(0x(B data.train_dataset       (0x(B path-to-imagenet-train-set                   (0x(B
(0x(B data.val_dataset         (0x(B path-to-imagenet-val-set                     (0x(B
(0x(B data.num_workers         (0x(B 12                                           (0x(B
(0x(B data.in_memory           (0x(B 1                                            (0x(B
(0x(B data.seed                (0x(B 0                                            (0x(B
(0x(B data.augmentations       (0x(B 1                                            (0x(B
(0x(B lr.step_ratio            (0x(B 0.1                                          (0x(B
(0x(B lr.step_length           (0x(B 30                                           (0x(B
(0x(B lr.lr_schedule_type      (0x(B cosine                                       (0x(B
(0x(B lr.lr                    (0x(B 0.005                                        (0x(B
(0x(B lr.lr_peak_epoch         (0x(B 20                                           (0x(B
(0x(B logging.folder           (0x(B ./folder/                                    (0x(B
(0x(B logging.log_level        (0x(B 2                                            (0x(B
(0x(B logging.save_freq        (0x(B 2                                            (0x(B
(0x(B logging.addendum         (0x(B additional_text_appended_to_save_folder_name (0x(B
(0x(B validation.batch_size    (0x(B 64                                           (0x(B
(0x(B validation.resolution    (0x(B 224                                          (0x(B
(0x(B validation.lr_tta        (0x(B 0                                            (0x(B
(0x(B validation.precision     (0x(B fp16                                         (0x(B
(0x(B training.eval_only       (0x(B 0                                            (0x(B
(0x(B training.batch_size      (0x(B 64                                           (0x(B
(0x(B training.optimizer       (0x(B adamw                                        (0x(B
(0x(B training.momentum        (0x(B 0.9                                          (0x(B
(0x(B training.weight_decay    (0x(B 0.05                                         (0x(B
(0x(B training.epochs          (0x(B 300                                          (0x(B
(0x(B training.label_smoothing (0x(B 0.1                                          (0x(B
(0x(B training.distributed     (0x(B 1                                            (0x(B
(0x(B training.use_blurpool    (0x(B 0                                            (0x(B
(0x(B training.precision       (0x(B fp16                                         (0x(B
(0x(B dist.world_size          (0x(B 1                                            (0x(B
(0x(B dist.address             (0x(B localhost                                    (0x(B
(0x(B dist.port                (0x(B 23456                                        (0x(B
(0x(B adv.attack               (0x(B none                                         (0x(B
(0x(B adv.norm                 (0x(B Linf                                         (0x(B
(0x(B adv.eps                  (0x(B 0.01568627450980392                          (0x(B
(0x(B adv.n_iter               (0x(B 2                                            (0x(B
(0x(B adv.verbose              (0x(B 0                                            (0x(B
(0x(B adv.noise_level          (0x(B 1.0                                          (0x(B
(0x(B adv.skip_projection      (0x(B 0                                            (0x(B
(0x(B adv.alpha                (0x(B 1.0                                          (0x(B
(0x(B misc.notes               (0x(B                                              (0x(B
(0x(B misc.use_channel_last    (0x(B 1                                            (0x(B
(0mqqqqqqqqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj(B
Transform = train: True
RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
MaybeToTensor()
Normalize(mean=tensor([0., 0., 0.]), std=tensor([1., 1., 1.]))
---------------------------
Number of the class = 100
Transform = train: False
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
---------------------------
Number of the class = 100
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f476f8c9280>
using channel last memory format
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): ConvBlock(
      (stem): Sequential(
        (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm()
        (2): GELU(approximate='none')
        (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm()
        (5): GELU(approximate='none')
        (6): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm()
        (8): GELU(approximate='none')
        (9): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm()
        (11): GELU(approximate='none')
        (12): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (fc_norm): Identity()
  (head_drop): Dropout(p=0.0, inplace=False)
  (head): Linear(in_features=768, out_features=100, bias=True)
)Unsupported operator aten::mean encountered 8 time(s)
Unsupported operator aten::sub encountered 8 time(s)
Unsupported operator aten::pow encountered 4 time(s)
Unsupported operator aten::add encountered 33 time(s)
Unsupported operator aten::sqrt encountered 4 time(s)
Unsupported operator aten::div encountered 4 time(s)
Unsupported operator aten::mul encountered 4 time(s)
Unsupported operator aten::gelu encountered 16 time(s)
Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.0.attn.attn_drop, blocks.1.attn.attn_drop, blocks.10.attn.attn_drop, blocks.11.attn.attn_drop, blocks.2.attn.attn_drop, blocks.3.attn.attn_drop, blocks.4.attn.attn_drop, blocks.5.attn.attn_drop, blocks.6.attn.attn_drop, blocks.7.attn.attn_drop, blocks.8.attn.attn_drop, blocks.9.attn.attn_drop

17215344384
17.215GFlops
| module                     | #parameters or shape   | #flops    |
|:---------------------------|:-----------------------|:----------|
| model                      | 86.455M                | 17.215G   |
|  cls_token                 |  (1, 1, 768)           |           |
|  pos_embed                 |  (1, 197, 768)         |           |
|  patch_embed.proj.stem     |  1.17M                 |  0.464G   |
|   patch_embed.proj.stem.0  |   1.344K               |   16.257M |
|   patch_embed.proj.stem.1  |   96                   |   0       |
|   patch_embed.proj.stem.3  |   41.568K              |   0.13G   |
|   patch_embed.proj.stem.4  |   0.192K               |   0       |
|   patch_embed.proj.stem.6  |   0.166M               |   0.13G   |
|   patch_embed.proj.stem.7  |   0.384K               |   0       |
|   patch_embed.proj.stem.9  |   0.664M               |   0.13G   |
|   patch_embed.proj.stem.10 |   0.768K               |   0       |
|   patch_embed.proj.stem.12 |   0.296M               |   57.803M |
|  blocks                    |  85.054M               |  16.75G   |
|   blocks.0                 |   7.088M               |   1.396G  |
|   blocks.1                 |   7.088M               |   1.396G  |
|   blocks.2                 |   7.088M               |   1.396G  |
|   blocks.3                 |   7.088M               |   1.396G  |
|   blocks.4                 |   7.088M               |   1.396G  |
|   blocks.5                 |   7.088M               |   1.396G  |
|   blocks.6                 |   7.088M               |   1.396G  |
|   blocks.7                 |   7.088M               |   1.396G  |
|   blocks.8                 |   7.088M               |   1.396G  |
|   blocks.9                 |   7.088M               |   1.396G  |
|   blocks.10                |   7.088M               |   1.396G  |
|   blocks.11                |   7.088M               |   1.396G  |
|  norm                      |  1.536K                |  0.756M   |
|   norm.weight              |   (768,)               |           |
|   norm.bias                |   (768,)               |           |
|  head                      |  76.9K                 |  76.8K    |
|   head.weight              |   (100, 768)           |           |
|   head.bias                |   (100,)               |           |
Counter({'linear': 16732204032, 'conv': 464228352, 'layer_norm': 18912000})
Using EMA with decay 0.9999
automatically exclude bn and bias from weight decay
=> Logging in /home/gwu3/code/revisiting-at/folder/model_2025-02-26 11:13:49_vit_b_upd_0_not_orig_1_pre_1_aug_1_clean_additional_text_appended_to_save_folder_name
  0%|          | 0/105 [00:00<?, ?it/s]  0%|          | 0/105 [00:10<?, ?it/s]  1%|          | 1/105 [01:10<2:02:50, 70.87s/it]100%|██████████| 105/105 [01:21<00:00,  1.29it/s]
clean accuracy=1.00%
=> Log: {'Validation acc': 0.009999999776482582, 'points': 10000.0}
  0%|          | 0/781 [00:00<?, ?it/s]  0%|          | 0/781 [00:18<?, ?it/s]epoch=0, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.666, acc=0.00%:   0%|          | 0/781 [01:23<?, ?it/s]epoch=0, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.666, acc=0.00%:   0%|          | 1/781 [01:23<18:03:18, 83.33s/it]epoch=0, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.666, acc=0.00%:   9%|▉         | 70/781 [01:53<15:01,  1.27s/it]  epoch=0, iter=100, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.647, acc=1.56%:   9%|▉         | 70/781 [02:06<15:01,  1.27s/it]epoch=0, iter=100, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.647, acc=1.56%:  18%|█▊        | 144/781 [02:23<07:57,  1.34it/s]epoch=0, iter=200, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.456, acc=4.69%:  18%|█▊        | 144/781 [02:49<07:57,  1.34it/s]epoch=0, iter=200, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.456, acc=4.69%:  27%|██▋       | 212/781 [02:53<05:50,  1.62it/s]epoch=0, iter=200, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.456, acc=4.69%:  36%|███▌      | 281/781 [03:24<04:33,  1.83it/s]epoch=0, iter=300, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.635, acc=3.12%:  36%|███▌      | 281/781 [03:34<04:33,  1.83it/s]epoch=0, iter=300, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.635, acc=3.12%:  44%|████▍     | 342/781 [03:54<03:52,  1.89it/s]epoch=0, iter=400, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.537, acc=4.69%:  44%|████▍     | 342/781 [04:20<03:52,  1.89it/s]epoch=0, iter=400, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.537, acc=4.69%:  53%|█████▎    | 411/781 [04:24<03:04,  2.01it/s]epoch=0, iter=400, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.537, acc=4.69%:  61%|██████    | 476/781 [04:54<02:28,  2.05it/s]epoch=0, iter=500, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.333, acc=6.25%:  61%|██████    | 476/781 [05:06<02:28,  2.05it/s]epoch=0, iter=500, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.333, acc=6.25%:  70%|██████▉   | 544/781 [05:25<01:52,  2.11it/s]epoch=0, iter=600, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.088, acc=7.81%:  70%|██████▉   | 544/781 [05:50<01:52,  2.11it/s]epoch=0, iter=600, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.088, acc=7.81%:  78%|███████▊  | 611/781 [05:55<01:19,  2.15it/s]epoch=0, iter=600, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.088, acc=7.81%:  87%|████████▋ | 680/781 [06:25<00:46,  2.18it/s]epoch=0, iter=700, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.265, acc=4.69%:  87%|████████▋ | 680/781 [06:36<00:46,  2.18it/s]epoch=0, iter=700, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.265, acc=4.69%:  95%|█████████▍| 741/781 [06:55<00:18,  2.13it/s]epoch=0, iter=780, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.333, acc=6.25%:  95%|█████████▍| 741/781 [07:14<00:18,  2.13it/s]epoch=0, iter=780, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.333, acc=6.25%: 100%|██████████| 781/781 [07:15<00:00,  1.79it/s]
=> Log: {'current_lr': 0.00025015492957746485, 'top_1': 0, 'top_5': 0, 'val_time': 0, 'train_loss': 4.440083980560303, 'train_acc': 0.043402777777777776, 'epoch': 0}
=> Log: {'current_lr': 0.00025015492957746485, 'top_1': 0, 'top_5': 0, 'val_time': 0, 'epoch': 0}
  0%|          | 0/781 [00:00<?, ?it/s]  0%|          | 0/781 [00:10<?, ?it/s]epoch=1, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.171, acc=6.25%:   0%|          | 0/781 [01:19<?, ?it/s]epoch=1, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.171, acc=6.25%:   0%|          | 1/781 [01:19<17:12:57, 79.46s/it]epoch=1, iter=0, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.171, acc=6.25%:   8%|▊         | 64/781 [01:49<16:09,  1.35s/it]  epoch=1, iter=100, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.262, acc=7.81%:   8%|▊         | 64/781 [02:07<16:09,  1.35s/it]epoch=1, iter=100, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.262, acc=7.81%:  16%|█▋        | 127/781 [02:20<09:10,  1.19it/s]epoch=1, iter=100, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.262, acc=7.81%:  24%|██▍       | 190/781 [02:50<06:41,  1.47it/s]epoch=1, iter=200, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.170, acc=7.81%:  24%|██▍       | 190/781 [02:55<06:41,  1.47it/s]epoch=1, iter=200, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.170, acc=7.81%:  33%|███▎      | 255/781 [03:20<05:11,  1.69it/s]epoch=1, iter=300, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.208, acc=7.81%:  33%|███▎      | 255/781 [03:43<05:11,  1.69it/s]epoch=1, iter=300, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.208, acc=7.81%:  41%|████      | 317/781 [03:51<04:18,  1.80it/s]epoch=1, iter=300, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.208, acc=7.81%:  48%|████▊     | 376/781 [04:21<03:39,  1.85it/s]epoch=1, iter=400, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.091, acc=10.94%:  48%|████▊     | 376/781 [04:33<03:39,  1.85it/s]epoch=1, iter=400, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.091, acc=10.94%:  56%|█████▋    | 441/781 [04:51<02:55,  1.94it/s]epoch=1, iter=500, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.239, acc=7.81%:  56%|█████▋    | 441/781 [05:18<02:55,  1.94it/s] epoch=1, iter=500, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.239, acc=7.81%:  65%|██████▌   | 511/781 [05:21<02:11,  2.05it/s]epoch=1, iter=500, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.239, acc=7.81%:  75%|███████▍  | 582/781 [05:51<01:32,  2.14it/s]epoch=1, iter=600, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.136, acc=10.94%:  75%|███████▍  | 582/781 [05:59<01:32,  2.14it/s]epoch=1, iter=600, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.136, acc=10.94%:  84%|████████▍ | 656/781 [06:22<00:55,  2.24it/s]epoch=1, iter=700, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.113, acc=3.12%:  84%|████████▍ | 656/781 [06:43<00:55,  2.24it/s] epoch=1, iter=700, shape=(64, 3, 224, 224), lrs=['0.000', '0.000'], loss=4.113, acc=3.12%:  92%|█████████▏| 720/781 [06:52<00:27,  2.20it/s]epoch=1, iter=780, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.100, acc=9.38%:  92%|█████████▏| 720/781 [07:22<00:27,  2.20it/s]epoch=1, iter=780, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.100, acc=9.38%: 100%|██████████| 781/781 [07:22<00:00,  2.14it/s]epoch=1, iter=780, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.100, acc=9.38%: 100%|██████████| 781/781 [07:23<00:00,  1.76it/s]
=> Log: {'current_lr': 0.0005001299295774649, 'top_1': 0, 'top_5': 0, 'val_time': 0, 'train_loss': 4.16565465927124, 'train_acc': 0.0798611111111111, 'epoch': 1}
=> Log: {'current_lr': 0.0005001299295774649, 'top_1': 0, 'top_5': 0, 'val_time': 0, 'epoch': 1}
  0%|          | 0/781 [00:00<?, ?it/s]  0%|          | 0/781 [00:17<?, ?it/s]epoch=2, iter=0, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=3.970, acc=9.38%:   0%|          | 0/781 [01:20<?, ?it/s]epoch=2, iter=0, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=3.970, acc=9.38%:   0%|          | 1/781 [01:20<17:27:05, 80.54s/it]epoch=2, iter=0, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=3.970, acc=9.38%:   8%|▊         | 64/781 [01:50<16:15,  1.36s/it]  epoch=2, iter=100, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.093, acc=6.25%:   8%|▊         | 64/781 [02:09<16:15,  1.36s/it]epoch=2, iter=100, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.093, acc=6.25%:  16%|█▌        | 126/781 [02:21<09:18,  1.17it/s]epoch=2, iter=100, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.093, acc=6.25%:  24%|██▍       | 190/781 [02:51<06:40,  1.48it/s]epoch=2, iter=200, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.292, acc=10.94%:  24%|██▍       | 190/781 [02:56<06:40,  1.48it/s]epoch=2, iter=200, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.292, acc=10.94%:  33%|███▎      | 256/781 [03:21<05:09,  1.70it/s]epoch=2, iter=300, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.184, acc=4.69%:  33%|███▎      | 256/781 [03:43<05:09,  1.70it/s] epoch=2, iter=300, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.184, acc=4.69%:  41%|████      | 319/781 [03:51<04:14,  1.82it/s]epoch=2, iter=300, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.184, acc=4.69%:  49%|████▊     | 379/781 [04:22<03:34,  1.87it/s]epoch=2, iter=400, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.254, acc=7.81%:  49%|████▊     | 379/781 [04:32<03:34,  1.87it/s]epoch=2, iter=400, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.254, acc=7.81%:  56%|█████▋    | 440/781 [04:52<02:58,  1.92it/s]epoch=2, iter=500, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.254, acc=10.94%:  56%|█████▋    | 440/781 [05:20<02:58,  1.92it/s]epoch=2, iter=500, shape=(64, 3, 224, 224), lrs=['0.001', '0.001'], loss=4.254, acc=10.94%:  65%|██████▍   | 505/781 [05:22<02:19,  1.98it/s]