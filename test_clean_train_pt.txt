(0l(B Arguments defined(0qqqqqqqqwqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk(B
(0x(B Parameter                (0x(B Value                                        (0x(B
(0tqqqqqqqqqqqqqqqqqqqqqqqqqqnqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqu(B
(0x(B model.arch               (0x(B vit_b                                        (0x(B
(0x(B model.pretrained         (0x(B 0                                            (0x(B
(0x(B model.ckpt_path          (0x(B ./vit_b_cvst_clean.pt                        (0x(B
(0x(B model.add_normalization  (0x(B 0                                            (0x(B
(0x(B model.not_original       (0x(B 1                                            (0x(B
(0x(B model.updated            (0x(B 0                                            (0x(B
(0x(B model.model_ema          (0x(B 1.0                                          (0x(B
(0x(B model.freeze_some        (0x(B 0                                            (0x(B
(0x(B model.early              (0x(B 1                                            (0x(B
(0x(B resolution.min_res       (0x(B 224                                          (0x(B
(0x(B resolution.max_res       (0x(B 224                                          (0x(B
(0x(B resolution.end_ramp      (0x(B 0                                            (0x(B
(0x(B resolution.start_ramp    (0x(B 0                                            (0x(B
(0x(B data.train_dataset       (0x(B path-to-imagenet-train-set                   (0x(B
(0x(B data.val_dataset         (0x(B path-to-imagenet-val-set                     (0x(B
(0x(B data.num_workers         (0x(B 12                                           (0x(B
(0x(B data.in_memory           (0x(B 1                                            (0x(B
(0x(B data.seed                (0x(B 0                                            (0x(B
(0x(B data.augmentations       (0x(B 1                                            (0x(B
(0x(B lr.step_ratio            (0x(B 0.1                                          (0x(B
(0x(B lr.step_length           (0x(B 30                                           (0x(B
(0x(B lr.lr_schedule_type      (0x(B step                                         (0x(B
(0x(B lr.lr                    (0x(B 0.0001                                       (0x(B
(0x(B lr.lr_peak_epoch         (0x(B 20                                           (0x(B
(0x(B logging.folder           (0x(B ./folder/                                    (0x(B
(0x(B logging.log_level        (0x(B 2                                            (0x(B
(0x(B logging.save_freq        (0x(B 2                                            (0x(B
(0x(B logging.addendum         (0x(B additional_text_appended_to_save_folder_name (0x(B
(0x(B validation.batch_size    (0x(B 64                                           (0x(B
(0x(B validation.resolution    (0x(B 224                                          (0x(B
(0x(B validation.lr_tta        (0x(B 0                                            (0x(B
(0x(B validation.precision     (0x(B fp16                                         (0x(B
(0x(B training.eval_only       (0x(B 0                                            (0x(B
(0x(B training.batch_size      (0x(B 64                                           (0x(B
(0x(B training.optimizer       (0x(B adamw                                        (0x(B
(0x(B training.momentum        (0x(B 0.9                                          (0x(B
(0x(B training.weight_decay    (0x(B 0.05                                         (0x(B
(0x(B training.epochs          (0x(B 300                                          (0x(B
(0x(B training.label_smoothing (0x(B 0.1                                          (0x(B
(0x(B training.distributed     (0x(B 1                                            (0x(B
(0x(B training.use_blurpool    (0x(B 0                                            (0x(B
(0x(B training.precision       (0x(B fp16                                         (0x(B
(0x(B dist.world_size          (0x(B 1                                            (0x(B
(0x(B dist.address             (0x(B localhost                                    (0x(B
(0x(B dist.port                (0x(B 54321                                        (0x(B
(0x(B adv.attack               (0x(B none                                         (0x(B
(0x(B adv.norm                 (0x(B Linf                                         (0x(B
(0x(B adv.eps                  (0x(B 0.01568627450980392                          (0x(B
(0x(B adv.n_iter               (0x(B 2                                            (0x(B
(0x(B adv.verbose              (0x(B 0                                            (0x(B
(0x(B adv.noise_level          (0x(B 1.0                                          (0x(B
(0x(B adv.skip_projection      (0x(B 0                                            (0x(B
(0x(B adv.alpha                (0x(B 1.0                                          (0x(B
(0x(B misc.notes               (0x(B                                              (0x(B
(0x(B misc.use_channel_last    (0x(B 1                                            (0x(B
(0mqqqqqqqqqqqqqqqqqqqqqqqqqqvqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj(B
Transform = train: True
RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
RandomHorizontalFlip(p=0.5)
RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
MaybeToTensor()
Normalize(mean=tensor([0., 0., 0.]), std=tensor([1., 1., 1.]))
---------------------------
Number of the class = 100
Transform = train: False
Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
CenterCrop(size=(224, 224))
ToTensor()
---------------------------
Number of the class = 100
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f96baf48580>
using channel last memory format
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): ConvBlock(
      (stem): Sequential(
        (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm()
        (2): GELU(approximate='none')
        (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm()
        (5): GELU(approximate='none')
        (6): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm()
        (8): GELU(approximate='none')
        (9): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm()
        (11): GELU(approximate='none')
        (12): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (fc_norm): Identity()
  (head_drop): Dropout(p=0.0, inplace=False)
  (head): Linear(in_features=768, out_features=100, bias=True)
)Unsupported operator aten::mean encountered 8 time(s)
Unsupported operator aten::sub encountered 8 time(s)
Unsupported operator aten::pow encountered 4 time(s)
Unsupported operator aten::add encountered 33 time(s)
Unsupported operator aten::sqrt encountered 4 time(s)
Unsupported operator aten::div encountered 4 time(s)
Unsupported operator aten::mul encountered 4 time(s)
Unsupported operator aten::gelu encountered 16 time(s)
Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.0.attn.attn_drop, blocks.1.attn.attn_drop, blocks.10.attn.attn_drop, blocks.11.attn.attn_drop, blocks.2.attn.attn_drop, blocks.3.attn.attn_drop, blocks.4.attn.attn_drop, blocks.5.attn.attn_drop, blocks.6.attn.attn_drop, blocks.7.attn.attn_drop, blocks.8.attn.attn_drop, blocks.9.attn.attn_drop

17215344384
17.215GFlops
| module                     | #parameters or shape   | #flops    |
|:---------------------------|:-----------------------|:----------|
| model                      | 86.455M                | 17.215G   |
|  cls_token                 |  (1, 1, 768)           |           |
|  pos_embed                 |  (1, 197, 768)         |           |
|  patch_embed.proj.stem     |  1.17M                 |  0.464G   |
|   patch_embed.proj.stem.0  |   1.344K               |   16.257M |
|   patch_embed.proj.stem.1  |   96                   |   0       |
|   patch_embed.proj.stem.3  |   41.568K              |   0.13G   |
|   patch_embed.proj.stem.4  |   0.192K               |   0       |
|   patch_embed.proj.stem.6  |   0.166M               |   0.13G   |
|   patch_embed.proj.stem.7  |   0.384K               |   0       |
|   patch_embed.proj.stem.9  |   0.664M               |   0.13G   |
|   patch_embed.proj.stem.10 |   0.768K               |   0       |
|   patch_embed.proj.stem.12 |   0.296M               |   57.803M |
|  blocks                    |  85.054M               |  16.75G   |
|   blocks.0                 |   7.088M               |   1.396G  |
|   blocks.1                 |   7.088M               |   1.396G  |
|   blocks.2                 |   7.088M               |   1.396G  |
|   blocks.3                 |   7.088M               |   1.396G  |
|   blocks.4                 |   7.088M               |   1.396G  |
|   blocks.5                 |   7.088M               |   1.396G  |
|   blocks.6                 |   7.088M               |   1.396G  |
|   blocks.7                 |   7.088M               |   1.396G  |
|   blocks.8                 |   7.088M               |   1.396G  |
|   blocks.9                 |   7.088M               |   1.396G  |
|   blocks.10                |   7.088M               |   1.396G  |
|   blocks.11                |   7.088M               |   1.396G  |
|  norm                      |  1.536K                |  0.756M   |
|   norm.weight              |   (768,)               |           |
|   norm.bias                |   (768,)               |           |
|  head                      |  76.9K                 |  76.8K    |
|   head.weight              |   (100, 768)           |           |
|   head.bias                |   (100,)               |           |
Counter({'linear': 16732204032, 'conv': 464228352, 'layer_norm': 18912000})
not loadï¼š {'head.bias', 'head.weight'}
Using EMA with decay 0.9999
automatically exclude bn and bias from weight decay
=> Logging in /home/gwu3/code/revisiting-at/folder/model_2025-02-26 15:25:01_vit_b_upd_0_not_orig_1_pre_0_aug_1_clean_additional_text_appended_to_save_folder_name
  0%|          | 0/105 [00:00<?, ?it/s]  0%|          | 0/105 [00:20<?, ?it/s]